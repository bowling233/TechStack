---
tags:
  - 读书笔记
  - 正在做
---

# 📖 深度学习

!!! abstract

    - **书名**：深度学习/Deep Learning
    - **年份**：2017
    - **书籍网站**：[deeplearningbook.org](https://www.deeplearningbook.org/)

在具体地进入人工智能的学习前，我们先来看看人工智能的发展历程，这对了解人工智能的发展脉络和其中的一些重要概念有很大帮助。

!!! note "知识库方法 Knowledge Base"

    将关于世界的知识用形式化的语言进行硬编码。计算机使用逻辑推理规则来自动理解这些形式化语言中的声明。

人工智能早期解决对人类智力来说非常困难，但对计算机来说相对简单的问题，比如抽象和形式化的任务。例子有：IBM 的深蓝国际象棋系统。

知识库方法遇到了困难，因为难以设计出足够复杂的形式化规则来精确地描述世界。最著名的知识库项目 Cyc 不能理解人在早上剃胡须：它知道人体的构成不含有电器零件，但由于人拿着剃须刀，它认为实体含有电器部件。因此它产生疑问：人在刮胡子时是否仍是一个人？

!!! note "机器学习 Machine Learning"

    系统具备自己获取知识的能力，能够从原始数据中提取模式。

    主要使用数理统计方法。

由人从数据中提取特征，将数据处理成结构化的形式，然后让机器学习算法从中提取模式。

但是，有很多任务我们很难知道如何提取特征。比如检测照片中的车，使用轮子作为特征吗？但图像可能因场景而异，轮子可能被遮挡，或者车可能是在水中。

!!! note "表示学习 Representation Learning"

    用机器学习来发掘表示本身，学习到的表示往往比手动设计的好。

    !!! note "自编码器 Autoencoder"

        由编码器函数和解码器函数组成，编码器将输入数据映射到表示空间，解码器将表示空间映射回原始数据空间。期望是输入数据经过编解码器后尽可能多地保留信息，同时希望新的表示有各种好的特性。

!!! note "深度学习 Deep Learning"

    一种机器学习技术，它使用神经网络来学习数据的表示形式。

    !!! note "前馈深度网络/多层感知机 Multilayer Perceptron"

        一种最简单的神经网络，由多个神经元组成的多层结构。

# 神经网络

首先，神经网络是一种机器学习的算法模型，以人脑和神经系统为模型。神经网络在模式识别等领域表现突出。

> 复习一下，机器学习指的是：计算机通过“阅读”训练数据提炼“意义”的过程，即计算机执行学习所需分析推理的算法。除了神经网络，机器学习五大反例还包括：基于案例推理、遗传算法、规则归纳和分析学习。

人工神经网络的思想来源于人脑和神经系统。学习是通过修改神经元之间连接的强度实现的，人工神经网络通过**改变权重**呈现这样的适应性。

## 模型

一个抽象的神经元具有：输入 $x$、权重 $w$、输出 $y$。我们用数学把它表达为：

$$
y=f(g(\overline{x}, \overline{w}))
$$

其中 $g$ 称为激励函数（一般是点乘），$f$ 是输出或激活函数。

人工神经网络就是抽象神经元按某种拓扑排列的集合，从数学上看作从 $R^n$ 到 $R^m$ 的映射 $F$。

接下来我们思考：为了让网络对某个输入产生特定的输出，如何让其调整权重？

## McCulloch-Pitts 网络

在该种网络中，神经元的输入、输出都是二进制的。输入通道称为边（edge），它可以是**兴奋或抑制**的。它的表现如下：

- 如果有抑制输入，那么输出为 0。
- 否则，当总激励大于阈值时，输出为 1。

可以看出，该神经元中激活函数 `f` 是一个阶跃函数。

> 书中展示了 McCulloch-Pitts 神经元实现的双输入门，如 AND、OR、NOR 和最小项的解码器，尝试回忆一下？

很显然，该网络因为没有权重而不能自适应。

## 感知器学习规则

一个神经网络，给出一个输入向量 $x$，存在一个期望的输出向量 $t$。网络按照**学习规则**调整权重，以最小化 $t$ 和 $y$ 之间的差异。

人工神经网络的学习规则主要有三种：感知器学习规则、增量规则和反向传播规则，其中反向传播能够用于多层网络。

TLU（Threshold Logic Unit）叫做阈值逻辑单元，它的输入输出同样是二进制的，具有以下参数：

- 输入向量
- 权重向量
- 阈值函数

神经网络的输入称为模式（pattern），表示所有输入的 $n$ 维空间称为模式空间。以双输入 TLU 为例，它的模式空间是平面上的四个点。我们也可以在模式空间中画出 TLU 在激励等于阈值时的直线。

相同输出的模式称为一个模式类，上面画出的直线就将两个模式类分开了。当模式空间维度为 $n$ 时，判别式的维数将会是 $n-1$，神经网络通过生成判别式，将 $n$ 维模式空间分割成以判别式超平面为边界的凸子空间，执行模式识别。

感知器学习规则通过迭代矫正来生成判别式。

将所有模式输入来训练神经网络，这一过程称为一个 epoch。如果处理完整个 epoch 而权重没有发生变化，则学习规则可以停止。

## 反向传播

感知器学习规则和增量规则要求：所实现的函数必须是线性可分离的。对于复杂的模式空间，应当使用反向传播规则，它可以工作在多层网络上。

> 神经网络的层数：输入层、输出层、隐藏层。一般来说，输入层仅作为输入点（没有权重），因此神经网络层数是隐藏层的层数加一，即权重的层数。

前馈（feed forward）网络：层 i 的神经元只与层 i+1 的神经元连接，无层内连接。

在完全连接的前馈网络中，每一层的权重都是一个矩阵。

反向传播要求激活函数是连续可微的，Sigmoid 函数 $S_c$ 常用于反向传播网络：

$$
f(x)=\frac{1}{1+e^{-cx}}
$$

如果 $c$ 较大，这个函数类似于阶跃函数。

Sigmoidal 单元的输入是

### 反向传播的训练过程

1. 将模式输入到网络中，计算输出，计算输出误差 $e$。
2. 重复 $N$ 次（$N$ 是模式的数目），得到平均误差 $E$。
3. 计算 $E$ 对于每一个权重的偏导数。
4. 给网络的每一个权重分配责任

